{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in ./venv/lib/python3.13/site-packages (1.1.1)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.3.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.13/site-packages (from pandas) (2.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DnrjRcVxX6SC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sMH0b1aSZttG"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CSV_FILE = \"files/git_repo_filtered_js_commit_date.csv\"\n",
        "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
        "GRAPHQL_URL = \"https://api.github.com/graphql\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n",
        "    \"Accept\": \"application/vnd.github+json\"\n",
        "}\n",
        "\n",
        "repos_from_csv = []\n",
        "\n",
        "repos_with_CI = set()\n",
        "invalid_repos = set()\n",
        "repos_with_no_workflows = set()\n",
        "repos_with_network_error = set()\n",
        "repo_name_to_branch = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgFPoYf2Z89i",
        "outputId": "bd4ba4ea-056c-4028-87a3-d58613397d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'owner': 'bigbluebutton', 'name': 'bigbluebutton', 'default_branch': 'v3.0.x-release'}, {'owner': 'zabinx', 'name': 'duskrpg', 'default_branch': 'master'}, {'owner': 'apache', 'name': 'cordova-android', 'default_branch': 'master'}, {'owner': 'aws-samples', 'name': 'aws-dynamodb-examples', 'default_branch': 'master'}, {'owner': 'dgarijo', 'name': 'widoco', 'default_branch': 'master'}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def read_filtered_repo_csvlist():\n",
        "    df = pd.read_csv(CSV_FILE)\n",
        "\n",
        "    # Split 'name' into owner and repo\n",
        "    for _, row in df.iterrows():\n",
        "        if '/' not in row['name']:\n",
        "            print(f\"Skipping invalid repo name: {row['name']}\")\n",
        "            continue\n",
        "        owner, repo_name = row['name'].split('/', 1)\n",
        "        repos_from_csv.append({\n",
        "            \"owner\": owner.strip(),\n",
        "            \"name\": repo_name.strip(),\n",
        "            \"default_branch\": row['default_branch'].strip()\n",
        "        })\n",
        "        repo_name_to_branch[f\"{owner.strip()}/{repo_name.strip()}\"] = row['default_branch'].strip()\n",
        "\n",
        "    print(repos_from_csv[:5])\n",
        "\n",
        "read_filtered_repo_csvlist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "R2Ra1Cy3aJKd"
      },
      "outputs": [],
      "source": [
        "# Step 2: Build GraphQL query for multiple repos\n",
        "def build_query_to_check_workflows(repos, start, end):\n",
        "    query_parts = []\n",
        "    for i, repo in enumerate(repos[start:end]):\n",
        "        query_parts.append(f\"\"\"\n",
        "        repo{i}: repository(owner: \"{repo['owner']}\", name: \"{repo['name']}\") {{\n",
        "            workflows: object(expression: \"{repo['default_branch']}:.github/workflows\") {{\n",
        "                ... on Tree {{\n",
        "                    entries {{\n",
        "                        name\n",
        "                        type\n",
        "                    }}\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "        \"\"\")\n",
        "    full_query = \"query { \" + \" \".join(query_parts) + \" }\"\n",
        "    # print(\"query:\", full_query)\n",
        "    return full_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6Me8Pr-Kdm2T"
      },
      "outputs": [],
      "source": [
        "# Step 3: Execute query and parse results\n",
        "def check_workflows(repos, start, end):\n",
        "    try:\n",
        "        query = build_query_to_check_workflows(repos, start, end)\n",
        "        response = requests.post(GRAPHQL_URL, json={\"query\": query}, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        # If GitHub responds with an error (403, 502, etc.)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Skipping batch {start}:{end} (HTTP {response.status_code})\")\n",
        "            for repo in repos[start:end]:\n",
        "                repos_with_network_error.add(f\"{repo['owner']}/{repo['name']}\")\n",
        "            return\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        for i, repo in enumerate(repos[start:end]):\n",
        "            key = f\"repo{i}\"\n",
        "            repo_data = data.get(\"data\", {}).get(key, {})\n",
        "\n",
        "            if not repo_data:\n",
        "                invalid_repos.add(f\"{repo['owner']}/{repo['name']}\")\n",
        "                continue\n",
        "            workflows = repo_data.get(\"workflows\")\n",
        "\n",
        "            if workflows and workflows.get(\"entries\"):\n",
        "                repos_with_CI.add(f\"{repo['owner']}/{repo['name']}\")\n",
        "            else:\n",
        "                repos_with_no_workflows.add(f\"{repo['owner']}/{repo['name']}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for batch {start}:{end}: {e}\")\n",
        "        for repo in repos[start:end]:\n",
        "            repos_with_network_error.add(f\"{repo['owner']}/{repo['name']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUMFpZUdotq",
        "outputId": "6055f9cd-0959-475d-9819-857737900fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 0 to 100. repos_with_CI:54 repos_with_network_error:0 repos_with_no_workflows:45 invalid_repos:1\n",
            "Processed 100 to 200. repos_with_CI:120 repos_with_network_error:0 repos_with_no_workflows:77 invalid_repos:3\n",
            "Processed 200 to 300. repos_with_CI:152 repos_with_network_error:0 repos_with_no_workflows:144 invalid_repos:4\n",
            "Processed 300 to 400. repos_with_CI:177 repos_with_network_error:0 repos_with_no_workflows:219 invalid_repos:4\n",
            "Processed 400 to 500. repos_with_CI:194 repos_with_network_error:0 repos_with_no_workflows:301 invalid_repos:5\n",
            "Processed 500 to 600. repos_with_CI:228 repos_with_network_error:0 repos_with_no_workflows:366 invalid_repos:6\n",
            "Processed 600 to 700. repos_with_CI:259 repos_with_network_error:0 repos_with_no_workflows:435 invalid_repos:6\n",
            "Processed 700 to 800. repos_with_CI:283 repos_with_network_error:0 repos_with_no_workflows:511 invalid_repos:6\n",
            "Processed 800 to 900. repos_with_CI:310 repos_with_network_error:0 repos_with_no_workflows:583 invalid_repos:7\n",
            "Processed 900 to 1000. repos_with_CI:338 repos_with_network_error:0 repos_with_no_workflows:655 invalid_repos:7\n",
            "Processed 1000 to 1100. repos_with_CI:373 repos_with_network_error:0 repos_with_no_workflows:720 invalid_repos:7\n",
            "Processed 1100 to 1200. repos_with_CI:412 repos_with_network_error:0 repos_with_no_workflows:781 invalid_repos:7\n",
            "Processed 1200 to 1300. repos_with_CI:457 repos_with_network_error:0 repos_with_no_workflows:836 invalid_repos:7\n",
            "Processed 1300 to 1400. repos_with_CI:490 repos_with_network_error:0 repos_with_no_workflows:902 invalid_repos:8\n",
            "Processed 1400 to 1500. repos_with_CI:537 repos_with_network_error:0 repos_with_no_workflows:955 invalid_repos:8\n",
            "Processed 1500 to 1600. repos_with_CI:582 repos_with_network_error:0 repos_with_no_workflows:1009 invalid_repos:9\n",
            "Processed 1600 to 1700. repos_with_CI:633 repos_with_network_error:0 repos_with_no_workflows:1058 invalid_repos:9\n",
            "Processed 1700 to 1800. repos_with_CI:686 repos_with_network_error:0 repos_with_no_workflows:1105 invalid_repos:9\n",
            "Processed 1800 to 1900. repos_with_CI:733 repos_with_network_error:0 repos_with_no_workflows:1158 invalid_repos:9\n",
            "Processed 1900 to 2000. repos_with_CI:777 repos_with_network_error:0 repos_with_no_workflows:1214 invalid_repos:9\n",
            "Processed 2000 to 2100. repos_with_CI:824 repos_with_network_error:0 repos_with_no_workflows:1266 invalid_repos:10\n",
            "Processed 2100 to 2200. repos_with_CI:869 repos_with_network_error:0 repos_with_no_workflows:1321 invalid_repos:10\n",
            "Processed 2200 to 2300. repos_with_CI:913 repos_with_network_error:0 repos_with_no_workflows:1376 invalid_repos:11\n",
            "Processed 2300 to 2400. repos_with_CI:965 repos_with_network_error:0 repos_with_no_workflows:1424 invalid_repos:11\n",
            "Processed 2400 to 2500. repos_with_CI:1014 repos_with_network_error:0 repos_with_no_workflows:1475 invalid_repos:11\n",
            "Processed 2500 to 2600. repos_with_CI:1059 repos_with_network_error:0 repos_with_no_workflows:1530 invalid_repos:11\n",
            "Processed 2600 to 2700. repos_with_CI:1116 repos_with_network_error:0 repos_with_no_workflows:1571 invalid_repos:13\n",
            "Processed 2700 to 2800. repos_with_CI:1156 repos_with_network_error:0 repos_with_no_workflows:1631 invalid_repos:13\n",
            "Processed 2800 to 2900. repos_with_CI:1205 repos_with_network_error:0 repos_with_no_workflows:1682 invalid_repos:13\n",
            "Processed 2900 to 3000. repos_with_CI:1256 repos_with_network_error:0 repos_with_no_workflows:1731 invalid_repos:13\n",
            "Processed 3000 to 3100. repos_with_CI:1310 repos_with_network_error:0 repos_with_no_workflows:1776 invalid_repos:14\n",
            "Processed 3100 to 3200. repos_with_CI:1366 repos_with_network_error:0 repos_with_no_workflows:1820 invalid_repos:14\n",
            "Processed 3200 to 3300. repos_with_CI:1413 repos_with_network_error:0 repos_with_no_workflows:1873 invalid_repos:14\n",
            "Processed 3300 to 3400. repos_with_CI:1466 repos_with_network_error:0 repos_with_no_workflows:1920 invalid_repos:14\n",
            "Processed 3400 to 3500. repos_with_CI:1513 repos_with_network_error:0 repos_with_no_workflows:1973 invalid_repos:14\n",
            "Processed 3500 to 3600. repos_with_CI:1565 repos_with_network_error:0 repos_with_no_workflows:2019 invalid_repos:16\n",
            "Processed 3600 to 3700. repos_with_CI:1618 repos_with_network_error:0 repos_with_no_workflows:2066 invalid_repos:16\n",
            "Processed 3700 to 3800. repos_with_CI:1674 repos_with_network_error:0 repos_with_no_workflows:2110 invalid_repos:16\n",
            "Processed 3800 to 3900. repos_with_CI:1730 repos_with_network_error:0 repos_with_no_workflows:2153 invalid_repos:17\n",
            "Processed 3900 to 4000. repos_with_CI:1786 repos_with_network_error:0 repos_with_no_workflows:2197 invalid_repos:17\n",
            "Processed 4000 to 4100. repos_with_CI:1836 repos_with_network_error:0 repos_with_no_workflows:2244 invalid_repos:20\n",
            "Processed 4100 to 4200. repos_with_CI:1886 repos_with_network_error:0 repos_with_no_workflows:2294 invalid_repos:20\n",
            "Processed 4200 to 4300. repos_with_CI:1947 repos_with_network_error:0 repos_with_no_workflows:2333 invalid_repos:20\n",
            "Processed 4300 to 4400. repos_with_CI:1996 repos_with_network_error:0 repos_with_no_workflows:2383 invalid_repos:21\n",
            "Processed 4400 to 4500. repos_with_CI:2053 repos_with_network_error:0 repos_with_no_workflows:2426 invalid_repos:21\n",
            "Processed 4500 to 4600. repos_with_CI:2116 repos_with_network_error:0 repos_with_no_workflows:2462 invalid_repos:22\n",
            "Processed 4600 to 4700. repos_with_CI:2176 repos_with_network_error:0 repos_with_no_workflows:2499 invalid_repos:25\n",
            "Processed 4700 to 4800. repos_with_CI:2229 repos_with_network_error:0 repos_with_no_workflows:2545 invalid_repos:26\n",
            "Processed 4800 to 4900. repos_with_CI:2286 repos_with_network_error:0 repos_with_no_workflows:2588 invalid_repos:26\n",
            "Processed 4900 to 5000. repos_with_CI:2346 repos_with_network_error:0 repos_with_no_workflows:2628 invalid_repos:26\n",
            "Processed 5000 to 5100. repos_with_CI:2391 repos_with_network_error:0 repos_with_no_workflows:2683 invalid_repos:26\n",
            "Processed 5100 to 5200. repos_with_CI:2447 repos_with_network_error:0 repos_with_no_workflows:2727 invalid_repos:26\n",
            "Processed 5200 to 5300. repos_with_CI:2516 repos_with_network_error:0 repos_with_no_workflows:2757 invalid_repos:27\n",
            "Processed 5300 to 5400. repos_with_CI:2577 repos_with_network_error:0 repos_with_no_workflows:2796 invalid_repos:27\n",
            "Processed 5400 to 5500. repos_with_CI:2651 repos_with_network_error:0 repos_with_no_workflows:2822 invalid_repos:27\n",
            "Processed 5500 to 5600. repos_with_CI:2706 repos_with_network_error:0 repos_with_no_workflows:2867 invalid_repos:27\n",
            "Processed 5600 to 5700. repos_with_CI:2769 repos_with_network_error:0 repos_with_no_workflows:2903 invalid_repos:28\n",
            "Processed 5700 to 5800. repos_with_CI:2830 repos_with_network_error:0 repos_with_no_workflows:2942 invalid_repos:28\n",
            "Processed 5800 to 5900. repos_with_CI:2887 repos_with_network_error:0 repos_with_no_workflows:2985 invalid_repos:28\n",
            "Processed 5900 to 6000. repos_with_CI:2940 repos_with_network_error:0 repos_with_no_workflows:3030 invalid_repos:30\n",
            "Processed 6000 to 6100. repos_with_CI:2995 repos_with_network_error:0 repos_with_no_workflows:3075 invalid_repos:30\n",
            "Processed 6100 to 6200. repos_with_CI:3055 repos_with_network_error:0 repos_with_no_workflows:3114 invalid_repos:31\n",
            "Processed 6200 to 6300. repos_with_CI:3116 repos_with_network_error:0 repos_with_no_workflows:3153 invalid_repos:31\n",
            "Processed 6300 to 6400. repos_with_CI:3186 repos_with_network_error:0 repos_with_no_workflows:3183 invalid_repos:31\n",
            "Processed 6400 to 6500. repos_with_CI:3247 repos_with_network_error:0 repos_with_no_workflows:3220 invalid_repos:33\n",
            "Processed 6500 to 6600. repos_with_CI:3311 repos_with_network_error:0 repos_with_no_workflows:3256 invalid_repos:33\n",
            "Processed 6600 to 6700. repos_with_CI:3379 repos_with_network_error:0 repos_with_no_workflows:3288 invalid_repos:33\n",
            "Processed 6700 to 6800. repos_with_CI:3449 repos_with_network_error:0 repos_with_no_workflows:3317 invalid_repos:34\n",
            "Processed 6800 to 6900. repos_with_CI:3501 repos_with_network_error:0 repos_with_no_workflows:3365 invalid_repos:34\n",
            "Processed 6900 to 7000. repos_with_CI:3569 repos_with_network_error:0 repos_with_no_workflows:3397 invalid_repos:34\n",
            "Processed 7000 to 7100. repos_with_CI:3631 repos_with_network_error:0 repos_with_no_workflows:3434 invalid_repos:35\n",
            "Processed 7100 to 7200. repos_with_CI:3699 repos_with_network_error:0 repos_with_no_workflows:3466 invalid_repos:35\n",
            "Processed 7200 to 7300. repos_with_CI:3762 repos_with_network_error:0 repos_with_no_workflows:3503 invalid_repos:35\n",
            "Processed 7300 to 7400. repos_with_CI:3829 repos_with_network_error:0 repos_with_no_workflows:3536 invalid_repos:35\n",
            "Processed 7400 to 7500. repos_with_CI:3894 repos_with_network_error:0 repos_with_no_workflows:3571 invalid_repos:35\n",
            "Processed 7500 to 7600. repos_with_CI:3973 repos_with_network_error:0 repos_with_no_workflows:3592 invalid_repos:35\n",
            "Processed 7600 to 7700. repos_with_CI:4043 repos_with_network_error:0 repos_with_no_workflows:3620 invalid_repos:37\n",
            "Processed 7700 to 7800. repos_with_CI:4114 repos_with_network_error:0 repos_with_no_workflows:3649 invalid_repos:37\n",
            "Processed 7800 to 7900. repos_with_CI:4174 repos_with_network_error:0 repos_with_no_workflows:3689 invalid_repos:37\n",
            "Processed 7900 to 8000. repos_with_CI:4248 repos_with_network_error:0 repos_with_no_workflows:3715 invalid_repos:37\n",
            "Processed 8000 to 8100. repos_with_CI:4311 repos_with_network_error:0 repos_with_no_workflows:3751 invalid_repos:38\n",
            "Processed 8100 to 8200. repos_with_CI:4386 repos_with_network_error:0 repos_with_no_workflows:3776 invalid_repos:38\n",
            "Processed 8200 to 8300. repos_with_CI:4450 repos_with_network_error:0 repos_with_no_workflows:3812 invalid_repos:38\n",
            "Processed 8300 to 8400. repos_with_CI:4521 repos_with_network_error:0 repos_with_no_workflows:3841 invalid_repos:38\n",
            "Processed 8400 to 8500. repos_with_CI:4597 repos_with_network_error:0 repos_with_no_workflows:3865 invalid_repos:38\n",
            "Processed 8500 to 8600. repos_with_CI:4681 repos_with_network_error:0 repos_with_no_workflows:3881 invalid_repos:38\n",
            "Request failed for batch 8600:8700: 502 Server Error: Bad Gateway for url: https://api.github.com/graphql\n",
            "Processed 8600 to 8700. repos_with_CI:4681 repos_with_network_error:100 repos_with_no_workflows:3881 invalid_repos:38\n",
            "Processed 8700 to 8800. repos_with_CI:4749 repos_with_network_error:100 repos_with_no_workflows:3912 invalid_repos:39\n",
            "Processed 8800 to 8900. repos_with_CI:4824 repos_with_network_error:100 repos_with_no_workflows:3936 invalid_repos:40\n",
            "Processed 8900 to 9000. repos_with_CI:4905 repos_with_network_error:100 repos_with_no_workflows:3952 invalid_repos:43\n",
            "Processed 9000 to 9100. repos_with_CI:4966 repos_with_network_error:100 repos_with_no_workflows:3991 invalid_repos:43\n",
            "Processed 9100 to 9200. repos_with_CI:5030 repos_with_network_error:100 repos_with_no_workflows:4027 invalid_repos:43\n",
            "Processed 9200 to 9300. repos_with_CI:5087 repos_with_network_error:100 repos_with_no_workflows:4070 invalid_repos:43\n",
            "Processed 9300 to 9400. repos_with_CI:5140 repos_with_network_error:100 repos_with_no_workflows:4117 invalid_repos:43\n",
            "Processed 9400 to 9500. repos_with_CI:5198 repos_with_network_error:100 repos_with_no_workflows:4159 invalid_repos:43\n",
            "Processed 9500 to 9600. repos_with_CI:5261 repos_with_network_error:100 repos_with_no_workflows:4196 invalid_repos:43\n",
            "Processed 9600 to 9700. repos_with_CI:5316 repos_with_network_error:100 repos_with_no_workflows:4240 invalid_repos:44\n",
            "Processed 9700 to 9800. repos_with_CI:5371 repos_with_network_error:100 repos_with_no_workflows:4284 invalid_repos:45\n",
            "Processed 9800 to 9900. repos_with_CI:5436 repos_with_network_error:100 repos_with_no_workflows:4319 invalid_repos:45\n",
            "Processed 9900 to 10000. repos_with_CI:5499 repos_with_network_error:100 repos_with_no_workflows:4356 invalid_repos:45\n",
            "Processed 10000 to 10100. repos_with_CI:5557 repos_with_network_error:100 repos_with_no_workflows:4396 invalid_repos:47\n",
            "Processed 10100 to 10200. repos_with_CI:5615 repos_with_network_error:100 repos_with_no_workflows:4438 invalid_repos:47\n",
            "Processed 10200 to 10300. repos_with_CI:5672 repos_with_network_error:100 repos_with_no_workflows:4479 invalid_repos:49\n",
            "Processed 10300 to 10400. repos_with_CI:5731 repos_with_network_error:100 repos_with_no_workflows:4518 invalid_repos:51\n",
            "Processed 10400 to 10500. repos_with_CI:5788 repos_with_network_error:100 repos_with_no_workflows:4560 invalid_repos:52\n",
            "Processed 10500 to 10600. repos_with_CI:5847 repos_with_network_error:100 repos_with_no_workflows:4600 invalid_repos:53\n",
            "Processed 10600 to 10700. repos_with_CI:5903 repos_with_network_error:100 repos_with_no_workflows:4644 invalid_repos:53\n",
            "Processed 10700 to 10800. repos_with_CI:5948 repos_with_network_error:100 repos_with_no_workflows:4698 invalid_repos:54\n",
            "Processed 10800 to 10900. repos_with_CI:5998 repos_with_network_error:100 repos_with_no_workflows:4747 invalid_repos:55\n",
            "Processed 10900 to 11000. repos_with_CI:6046 repos_with_network_error:100 repos_with_no_workflows:4799 invalid_repos:55\n",
            "Processed 11000 to 11100. repos_with_CI:6093 repos_with_network_error:100 repos_with_no_workflows:4851 invalid_repos:56\n",
            "Processed 11100 to 11200. repos_with_CI:6146 repos_with_network_error:100 repos_with_no_workflows:4898 invalid_repos:56\n",
            "Processed 11200 to 11300. repos_with_CI:6201 repos_with_network_error:100 repos_with_no_workflows:4942 invalid_repos:57\n",
            "Processed 11300 to 11400. repos_with_CI:6249 repos_with_network_error:100 repos_with_no_workflows:4994 invalid_repos:57\n",
            "Processed 11400 to 11500. repos_with_CI:6297 repos_with_network_error:100 repos_with_no_workflows:5046 invalid_repos:57\n",
            "Processed 11500 to 11600. repos_with_CI:6346 repos_with_network_error:100 repos_with_no_workflows:5096 invalid_repos:58\n",
            "Processed 11600 to 11700. repos_with_CI:6403 repos_with_network_error:100 repos_with_no_workflows:5137 invalid_repos:60\n",
            "Processed 11700 to 11800. repos_with_CI:6453 repos_with_network_error:100 repos_with_no_workflows:5186 invalid_repos:61\n",
            "Processed 11800 to 11900. repos_with_CI:6512 repos_with_network_error:100 repos_with_no_workflows:5226 invalid_repos:62\n",
            "Processed 11900 to 12000. repos_with_CI:6570 repos_with_network_error:100 repos_with_no_workflows:5266 invalid_repos:64\n",
            "Processed 12000 to 12100. repos_with_CI:6620 repos_with_network_error:100 repos_with_no_workflows:5314 invalid_repos:66\n",
            "Processed 12100 to 12200. repos_with_CI:6675 repos_with_network_error:100 repos_with_no_workflows:5356 invalid_repos:69\n",
            "Processed 12200 to 12300. repos_with_CI:6732 repos_with_network_error:100 repos_with_no_workflows:5397 invalid_repos:71\n",
            "Processed 12300 to 12400. repos_with_CI:6782 repos_with_network_error:100 repos_with_no_workflows:5447 invalid_repos:71\n",
            "Processed 12400 to 12500. repos_with_CI:6839 repos_with_network_error:100 repos_with_no_workflows:5490 invalid_repos:71\n",
            "Processed 12500 to 12600. repos_with_CI:6892 repos_with_network_error:100 repos_with_no_workflows:5535 invalid_repos:73\n",
            "Processed 12600 to 12700. repos_with_CI:6951 repos_with_network_error:100 repos_with_no_workflows:5576 invalid_repos:73\n",
            "Processed 12700 to 12800. repos_with_CI:7002 repos_with_network_error:100 repos_with_no_workflows:5622 invalid_repos:76\n",
            "Processed 12800 to 12900. repos_with_CI:7054 repos_with_network_error:100 repos_with_no_workflows:5668 invalid_repos:78\n",
            "Processed 12900 to 13000. repos_with_CI:7106 repos_with_network_error:100 repos_with_no_workflows:5713 invalid_repos:81\n",
            "Processed 13000 to 13100. repos_with_CI:7147 repos_with_network_error:100 repos_with_no_workflows:5772 invalid_repos:81\n",
            "Processed 13100 to 13200. repos_with_CI:7205 repos_with_network_error:100 repos_with_no_workflows:5814 invalid_repos:81\n",
            "Processed 13200 to 13300. repos_with_CI:7259 repos_with_network_error:100 repos_with_no_workflows:5859 invalid_repos:82\n",
            "Processed 13300 to 13400. repos_with_CI:7307 repos_with_network_error:100 repos_with_no_workflows:5911 invalid_repos:82\n",
            "Processed 13400 to 13500. repos_with_CI:7349 repos_with_network_error:100 repos_with_no_workflows:5969 invalid_repos:82\n",
            "Processed 13500 to 13600. repos_with_CI:7406 repos_with_network_error:100 repos_with_no_workflows:6011 invalid_repos:83\n",
            "Processed 13600 to 13700. repos_with_CI:7456 repos_with_network_error:100 repos_with_no_workflows:6059 invalid_repos:85\n",
            "Processed 13700 to 13800. repos_with_CI:7513 repos_with_network_error:100 repos_with_no_workflows:6101 invalid_repos:86\n",
            "Processed 13800 to 13900. repos_with_CI:7555 repos_with_network_error:100 repos_with_no_workflows:6159 invalid_repos:86\n",
            "Processed 13900 to 14000. repos_with_CI:7612 repos_with_network_error:100 repos_with_no_workflows:6201 invalid_repos:87\n",
            "Processed 14000 to 14100. repos_with_CI:7660 repos_with_network_error:100 repos_with_no_workflows:6252 invalid_repos:88\n",
            "Processed 14100 to 14200. repos_with_CI:7706 repos_with_network_error:100 repos_with_no_workflows:6304 invalid_repos:90\n",
            "Processed 14200 to 14300. repos_with_CI:7768 repos_with_network_error:100 repos_with_no_workflows:6341 invalid_repos:91\n",
            "Processed 14300 to 14400. repos_with_CI:7811 repos_with_network_error:100 repos_with_no_workflows:6397 invalid_repos:92\n",
            "Processed 14400 to 14500. repos_with_CI:7854 repos_with_network_error:100 repos_with_no_workflows:6454 invalid_repos:92\n",
            "Processed 14500 to 14600. repos_with_CI:7910 repos_with_network_error:100 repos_with_no_workflows:6495 invalid_repos:95\n",
            "Processed 14600 to 14700. repos_with_CI:7954 repos_with_network_error:100 repos_with_no_workflows:6547 invalid_repos:99\n",
            "Processed 14700 to 14800. repos_with_CI:8009 repos_with_network_error:100 repos_with_no_workflows:6592 invalid_repos:99\n",
            "Processed 14800 to 14900. repos_with_CI:8055 repos_with_network_error:100 repos_with_no_workflows:6645 invalid_repos:100\n",
            "Processed 14900 to 15000. repos_with_CI:8106 repos_with_network_error:100 repos_with_no_workflows:6692 invalid_repos:102\n",
            "Processed 15000 to 15100. repos_with_CI:8153 repos_with_network_error:100 repos_with_no_workflows:6744 invalid_repos:103\n",
            "Processed 15100 to 15200. repos_with_CI:8208 repos_with_network_error:100 repos_with_no_workflows:6787 invalid_repos:105\n",
            "Processed 15200 to 15300. repos_with_CI:8262 repos_with_network_error:100 repos_with_no_workflows:6833 invalid_repos:105\n",
            "Processed 15300 to 15400. repos_with_CI:8316 repos_with_network_error:100 repos_with_no_workflows:6879 invalid_repos:105\n",
            "Processed 15400 to 15500. repos_with_CI:8357 repos_with_network_error:100 repos_with_no_workflows:6938 invalid_repos:105\n",
            "Processed 15500 to 15600. repos_with_CI:8406 repos_with_network_error:100 repos_with_no_workflows:6985 invalid_repos:109\n",
            "Processed 15600 to 15700. repos_with_CI:8462 repos_with_network_error:100 repos_with_no_workflows:7028 invalid_repos:110\n",
            "Processed 15700 to 15800. repos_with_CI:8521 repos_with_network_error:100 repos_with_no_workflows:7067 invalid_repos:112\n",
            "Processed 15800 to 15900. repos_with_CI:8575 repos_with_network_error:100 repos_with_no_workflows:7112 invalid_repos:113\n",
            "Processed 15900 to 16000. repos_with_CI:8629 repos_with_network_error:100 repos_with_no_workflows:7156 invalid_repos:115\n",
            "Processed 16000 to 16100. repos_with_CI:8679 repos_with_network_error:100 repos_with_no_workflows:7205 invalid_repos:116\n",
            "Processed 16100 to 16200. repos_with_CI:8734 repos_with_network_error:100 repos_with_no_workflows:7249 invalid_repos:117\n",
            "Processed 16200 to 16300. repos_with_CI:8782 repos_with_network_error:100 repos_with_no_workflows:7299 invalid_repos:119\n",
            "Processed 16300 to 16400. repos_with_CI:8821 repos_with_network_error:100 repos_with_no_workflows:7360 invalid_repos:119\n",
            "Processed 16400 to 16500. repos_with_CI:8864 repos_with_network_error:100 repos_with_no_workflows:7415 invalid_repos:121\n",
            "Processed 16500 to 16600. repos_with_CI:8912 repos_with_network_error:100 repos_with_no_workflows:7466 invalid_repos:122\n",
            "Processed 16600 to 16700. repos_with_CI:8955 repos_with_network_error:100 repos_with_no_workflows:7520 invalid_repos:125\n",
            "Request failed for batch 16700:16800: 502 Server Error: Bad Gateway for url: https://api.github.com/graphql\n",
            "Processed 16700 to 16800. repos_with_CI:8955 repos_with_network_error:200 repos_with_no_workflows:7520 invalid_repos:125\n",
            "Processed 16800 to 16900. repos_with_CI:9020 repos_with_network_error:200 repos_with_no_workflows:7553 invalid_repos:127\n",
            "Processed 16900 to 17000. repos_with_CI:9081 repos_with_network_error:200 repos_with_no_workflows:7591 invalid_repos:128\n",
            "Processed 17000 to 17100. repos_with_CI:9129 repos_with_network_error:200 repos_with_no_workflows:7641 invalid_repos:130\n",
            "Processed 17100 to 17200. repos_with_CI:9189 repos_with_network_error:200 repos_with_no_workflows:7679 invalid_repos:132\n",
            "Processed 17200 to 17300. repos_with_CI:9245 repos_with_network_error:200 repos_with_no_workflows:7717 invalid_repos:138\n",
            "Processed 17300 to 17400. repos_with_CI:9293 repos_with_network_error:200 repos_with_no_workflows:7767 invalid_repos:140\n",
            "Processed 17400 to 17500. repos_with_CI:9349 repos_with_network_error:200 repos_with_no_workflows:7810 invalid_repos:141\n",
            "Processed 17500 to 17600. repos_with_CI:9380 repos_with_network_error:200 repos_with_no_workflows:7877 invalid_repos:143\n",
            "Processed 17600 to 17700. repos_with_CI:9423 repos_with_network_error:200 repos_with_no_workflows:7932 invalid_repos:145\n",
            "Processed 17700 to 17800. repos_with_CI:9455 repos_with_network_error:200 repos_with_no_workflows:7999 invalid_repos:146\n",
            "Processed 17800 to 17900. repos_with_CI:9491 repos_with_network_error:200 repos_with_no_workflows:8062 invalid_repos:147\n",
            "Processed 17900 to 18000. repos_with_CI:9527 repos_with_network_error:200 repos_with_no_workflows:8125 invalid_repos:148\n",
            "Processed 18000 to 18100. repos_with_CI:9560 repos_with_network_error:200 repos_with_no_workflows:8191 invalid_repos:149\n",
            "Processed 18100 to 18200. repos_with_CI:9597 repos_with_network_error:200 repos_with_no_workflows:8254 invalid_repos:149\n",
            "Processed 18200 to 18300. repos_with_CI:9639 repos_with_network_error:200 repos_with_no_workflows:8311 invalid_repos:150\n",
            "Processed 18300 to 18400. repos_with_CI:9680 repos_with_network_error:200 repos_with_no_workflows:8370 invalid_repos:150\n",
            "Processed 18400 to 18500. repos_with_CI:9725 repos_with_network_error:200 repos_with_no_workflows:8424 invalid_repos:151\n",
            "Processed 18500 to 18600. repos_with_CI:9770 repos_with_network_error:200 repos_with_no_workflows:8478 invalid_repos:152\n",
            "Processed 18600 to 18700. repos_with_CI:9807 repos_with_network_error:200 repos_with_no_workflows:8536 invalid_repos:157\n",
            "Processed 18700 to 18800. repos_with_CI:9853 repos_with_network_error:200 repos_with_no_workflows:8589 invalid_repos:158\n",
            "Processed 18800 to 18900. repos_with_CI:9909 repos_with_network_error:200 repos_with_no_workflows:8628 invalid_repos:163\n",
            "Processed 18900 to 19000. repos_with_CI:9960 repos_with_network_error:200 repos_with_no_workflows:8673 invalid_repos:167\n",
            "Processed 19000 to 19100. repos_with_CI:10023 repos_with_network_error:200 repos_with_no_workflows:8710 invalid_repos:167\n",
            "Processed 19100 to 19200. repos_with_CI:10086 repos_with_network_error:200 repos_with_no_workflows:8743 invalid_repos:171\n",
            "Processed 19200 to 19300. repos_with_CI:10133 repos_with_network_error:200 repos_with_no_workflows:8792 invalid_repos:175\n",
            "Processed 19300 to 19400. repos_with_CI:10174 repos_with_network_error:200 repos_with_no_workflows:8846 invalid_repos:180\n",
            "Processed 19400 to 19500. repos_with_CI:10210 repos_with_network_error:200 repos_with_no_workflows:8908 invalid_repos:182\n",
            "Processed 19500 to 19600. repos_with_CI:10270 repos_with_network_error:200 repos_with_no_workflows:8943 invalid_repos:187\n",
            "Processed 19600 to 19700. repos_with_CI:10317 repos_with_network_error:200 repos_with_no_workflows:8991 invalid_repos:192\n",
            "Processed 19700 to 19800. repos_with_CI:10358 repos_with_network_error:200 repos_with_no_workflows:9048 invalid_repos:194\n",
            "Processed 19800 to 19900. repos_with_CI:10404 repos_with_network_error:200 repos_with_no_workflows:9094 invalid_repos:202\n",
            "Processed 19900 to 20000. repos_with_CI:10455 repos_with_network_error:200 repos_with_no_workflows:9138 invalid_repos:207\n",
            "Processed 20000 to 20100. repos_with_CI:10495 repos_with_network_error:200 repos_with_no_workflows:9198 invalid_repos:207\n",
            "Processed 20100 to 20200. repos_with_CI:10541 repos_with_network_error:200 repos_with_no_workflows:9252 invalid_repos:207\n",
            "Processed 20200 to 20300. repos_with_CI:10568 repos_with_network_error:200 repos_with_no_workflows:9319 invalid_repos:213\n",
            "Processed 20300 to 20400. repos_with_CI:10601 repos_with_network_error:200 repos_with_no_workflows:9384 invalid_repos:215\n",
            "Processed 20400 to 20500. repos_with_CI:10641 repos_with_network_error:200 repos_with_no_workflows:9441 invalid_repos:218\n",
            "Processed 20500 to 20600. repos_with_CI:10679 repos_with_network_error:200 repos_with_no_workflows:9498 invalid_repos:223\n",
            "Processed 20600 to 20700. repos_with_CI:10731 repos_with_network_error:200 repos_with_no_workflows:9542 invalid_repos:227\n",
            "Processed 20700 to 20800. repos_with_CI:10783 repos_with_network_error:200 repos_with_no_workflows:9586 invalid_repos:231\n",
            "Processed 20800 to 20900. repos_with_CI:10830 repos_with_network_error:200 repos_with_no_workflows:9634 invalid_repos:236\n",
            "Processed 20900 to 21000. repos_with_CI:10868 repos_with_network_error:200 repos_with_no_workflows:9690 invalid_repos:242\n",
            "Processed 21000 to 21100. repos_with_CI:10912 repos_with_network_error:200 repos_with_no_workflows:9739 invalid_repos:249\n",
            "Processed 21100 to 21200. repos_with_CI:10959 repos_with_network_error:200 repos_with_no_workflows:9787 invalid_repos:254\n",
            "Processed 21200 to 21300. repos_with_CI:10995 repos_with_network_error:200 repos_with_no_workflows:9845 invalid_repos:260\n",
            "Processed 21300 to 21400. repos_with_CI:11026 repos_with_network_error:200 repos_with_no_workflows:9910 invalid_repos:264\n",
            "Processed 21400 to 21500. repos_with_CI:11058 repos_with_network_error:200 repos_with_no_workflows:9974 invalid_repos:268\n",
            "Processed 21500 to 21600. repos_with_CI:11093 repos_with_network_error:200 repos_with_no_workflows:10038 invalid_repos:269\n",
            "Processed 21600 to 21700. repos_with_CI:11130 repos_with_network_error:200 repos_with_no_workflows:10098 invalid_repos:272\n",
            "Processed 21700 to 21800. repos_with_CI:11173 repos_with_network_error:200 repos_with_no_workflows:10153 invalid_repos:274\n",
            "Processed 21800 to 21900. repos_with_CI:11218 repos_with_network_error:200 repos_with_no_workflows:10204 invalid_repos:278\n",
            "Processed 21900 to 22000. repos_with_CI:11248 repos_with_network_error:200 repos_with_no_workflows:10269 invalid_repos:283\n",
            "Processed 22000 to 22100. repos_with_CI:11279 repos_with_network_error:200 repos_with_no_workflows:10333 invalid_repos:288\n",
            "Processed 22100 to 22200. repos_with_CI:11309 repos_with_network_error:200 repos_with_no_workflows:10398 invalid_repos:293\n",
            "Processed 22200 to 22300. repos_with_CI:11349 repos_with_network_error:200 repos_with_no_workflows:10456 invalid_repos:295\n",
            "Processed 22300 to 22400. repos_with_CI:11394 repos_with_network_error:200 repos_with_no_workflows:10507 invalid_repos:299\n",
            "Processed 22400 to 22500. repos_with_CI:11425 repos_with_network_error:200 repos_with_no_workflows:10569 invalid_repos:306\n",
            "Processed 22500 to 22600. repos_with_CI:11458 repos_with_network_error:200 repos_with_no_workflows:10633 invalid_repos:309\n",
            "Processed 22600 to 22700. repos_with_CI:11480 repos_with_network_error:200 repos_with_no_workflows:10707 invalid_repos:313\n",
            "Processed 22700 to 22800. repos_with_CI:11521 repos_with_network_error:200 repos_with_no_workflows:10764 invalid_repos:315\n",
            "Processed 22800 to 22900. repos_with_CI:11549 repos_with_network_error:200 repos_with_no_workflows:10832 invalid_repos:319\n",
            "Processed 22900 to 23000. repos_with_CI:11584 repos_with_network_error:200 repos_with_no_workflows:10890 invalid_repos:326\n",
            "Processed 23000 to 23100. repos_with_CI:11617 repos_with_network_error:200 repos_with_no_workflows:10952 invalid_repos:331\n",
            "Processed 23100 to 23200. repos_with_CI:11650 repos_with_network_error:200 repos_with_no_workflows:11013 invalid_repos:337\n",
            "Processed 23200 to 23300. repos_with_CI:11684 repos_with_network_error:200 repos_with_no_workflows:11075 invalid_repos:341\n",
            "Processed 23300 to 23400. repos_with_CI:11723 repos_with_network_error:200 repos_with_no_workflows:11132 invalid_repos:345\n",
            "Processed 23400 to 23500. repos_with_CI:11755 repos_with_network_error:200 repos_with_no_workflows:11197 invalid_repos:348\n",
            "Processed 23500 to 23600. repos_with_CI:11785 repos_with_network_error:200 repos_with_no_workflows:11260 invalid_repos:355\n",
            "Processed 23600 to 23700. repos_with_CI:11808 repos_with_network_error:200 repos_with_no_workflows:11326 invalid_repos:366\n",
            "Processed 23700 to 23800. repos_with_CI:11836 repos_with_network_error:200 repos_with_no_workflows:11392 invalid_repos:372\n",
            "Processed 23800 to 23900. repos_with_CI:11867 repos_with_network_error:200 repos_with_no_workflows:11455 invalid_repos:378\n",
            "Processed 23900 to 24000. repos_with_CI:11894 repos_with_network_error:200 repos_with_no_workflows:11522 invalid_repos:384\n",
            "Processed 24000 to 24100. repos_with_CI:11931 repos_with_network_error:200 repos_with_no_workflows:11578 invalid_repos:391\n",
            "Processed 24100 to 24200. repos_with_CI:11951 repos_with_network_error:200 repos_with_no_workflows:11649 invalid_repos:400\n",
            "Processed 24200 to 24300. repos_with_CI:11985 repos_with_network_error:200 repos_with_no_workflows:11704 invalid_repos:411\n",
            "Processed 24300 to 24400. repos_with_CI:12013 repos_with_network_error:200 repos_with_no_workflows:11765 invalid_repos:422\n",
            "Processed 24400 to 24500. repos_with_CI:12052 repos_with_network_error:200 repos_with_no_workflows:11822 invalid_repos:426\n",
            "Processed 24500 to 24600. repos_with_CI:12083 repos_with_network_error:200 repos_with_no_workflows:11888 invalid_repos:429\n",
            "Processed 24600 to 24612. repos_with_CI:12085 repos_with_network_error:200 repos_with_no_workflows:11898 invalid_repos:429\n"
          ]
        }
      ],
      "source": [
        "start = 0\n",
        "batch_size = 100\n",
        "limit = len(repos_from_csv)\n",
        "\n",
        "repos_with_CI = set()\n",
        "invalid_repos = set()\n",
        "repos_with_no_workflows = set()\n",
        "repos_with_network_error = set()\n",
        "\n",
        "for start in range(start, limit, batch_size):\n",
        "    end = min(start + batch_size, limit)\n",
        "    check_workflows(repos_from_csv, start, end)\n",
        "    print(f\"Processed {start} to {end}. repos_with_CI:{len(repos_with_CI)} repos_with_network_error:{len(repos_with_network_error)} repos_with_no_workflows:{len(repos_with_no_workflows)} invalid_repos:{len(invalid_repos)}\")\n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ALEpLHlNCZGv"
      },
      "outputs": [],
      "source": [
        "# Save each set to a separate file\n",
        "def save_repo_names_to_file():\n",
        "    with open(\"files/repos_with_CI.txt\", \"w\") as f:\n",
        "        for repo in (repos_with_CI):\n",
        "            f.write(repo + \"\\n\")\n",
        "\n",
        "    with open(\"files/repos_with_no_workflows.txt\", \"w\") as f:\n",
        "        for repo in (repos_with_no_workflows):\n",
        "            f.write(repo + \"\\n\")\n",
        "\n",
        "    with open(\"files/invalid_repos.txt\", \"w\") as f:\n",
        "        for repo in (invalid_repos):\n",
        "            f.write(repo + \"\\n\")\n",
        "\n",
        "    with open(\"files/repos_with_network_error.txt\", \"w\") as f:\n",
        "        for repo in (repos_with_network_error):\n",
        "            f.write(repo + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_repo_names_to_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49-8mop-C-vl",
        "outputId": "ca310106-dc47-4564-97e2-620696d68e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repos_with_CI:12215, repos_with_network_error: 0\n"
          ]
        }
      ],
      "source": [
        "# retrying repos with network error\n",
        "unchecked_repos = []\n",
        "for error_repo in repos_with_network_error:\n",
        "    owner, repo_name = error_repo.split('/', 1)\n",
        "    unchecked_repos.append({\n",
        "        \"owner\": owner.strip(),\n",
        "        \"name\": repo_name.strip(),\n",
        "        \"default_branch\": repo_name_to_branch[f\"{owner.strip()}/{repo_name.strip()}\"].strip()\n",
        "    })\n",
        "\n",
        "batch_size = 100\n",
        "repos_with_network_error = set()\n",
        "\n",
        "for start in range(0, len(unchecked_repos), batch_size):\n",
        "    end = min(start + batch_size, limit)\n",
        "    check_workflows(unchecked_repos, start, end)\n",
        "\n",
        "print(f'repos_with_CI:{len(repos_with_CI)}, repos_with_network_error: {len(repos_with_network_error)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-4TDGazOOkyX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repos_with_CI:12215 repos_with_network_error:0 repos_with_no_workflows:11965 invalid_repos:432\n"
          ]
        }
      ],
      "source": [
        "save_repo_names_to_file()\n",
        "print(f\"repos_with_CI:{len(repos_with_CI)} repos_with_network_error:{len(repos_with_network_error)} repos_with_no_workflows:{len(repos_with_no_workflows)} invalid_repos:{len(invalid_repos)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "repos_with_CI:12215\n"
          ]
        }
      ],
      "source": [
        "# read from saved files\n",
        "repos_list_with_CI = []\n",
        "\n",
        "with open(\"files/repos_with_CI.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        repos_list_with_CI.append(line.lower())\n",
        "\n",
        "print(f\"repos_with_CI:{len(repos_with_CI)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_query_for_download_workflows(start, end, repos_list):\n",
        "    query_parts = []\n",
        "    for idx, repo_full in enumerate(repos_list[start:end]):\n",
        "        owner, name = [x.strip() for x in repo_full.split(\"/\")]\n",
        "        query_parts.append(f\"\"\"\n",
        "        repo{idx}: repository(owner: \"{owner}\", name: \"{name}\") {{\n",
        "            object(expression: \"HEAD:.github/workflows\") {{\n",
        "                ... on Tree {{\n",
        "                    entries {{\n",
        "                        name\n",
        "                        type\n",
        "                        object {{\n",
        "                            ... on Blob {{\n",
        "                                text\n",
        "                            }}\n",
        "                        }}\n",
        "                    }}\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "        \"\"\")\n",
        "    return \"query {\\n\" + \"\\n\".join(query_parts) + \"\\n}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_workflows(repos_list):\n",
        "    start = 0\n",
        "    batch_size = 50\n",
        "    limit = len(repos_list)\n",
        "    sleep_time = 3\n",
        "    workflow_files = \"workflow_files\"\n",
        "\n",
        "    for start in range(start, limit, batch_size):\n",
        "        time.sleep(sleep_time)  # To respect rate limits\n",
        "        print(f\"Processing chunk {start} to {min(start + batch_size, limit)}\")\n",
        "        try:\n",
        "            end = min(start + batch_size, limit)\n",
        "            query = build_query_for_download_workflows(start, end, repos_list)\n",
        "            response = requests.post(\n",
        "                \"https://api.github.com/graphql\",\n",
        "                json={\"query\": query},\n",
        "                headers=HEADERS,\n",
        "                timeout=30  # Optional: avoid hanging\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            data = response.json().get(\"data\", {})\n",
        "\n",
        "            for idx, repo_full in enumerate(repos_list[start:end]):\n",
        "                owner, repo_name = repo_full.split(\"/\")\n",
        "                repo_key = f\"repo{idx}\"\n",
        "\n",
        "                if(data.get(repo_key, {}) is None or data.get(repo_key, {}).get(\"object\") is None):\n",
        "                    print(f\"Data missing {repo_full}\")\n",
        "                    continue\n",
        "\n",
        "                entries = data.get(repo_key, {}).get(\"object\", {}).get(\"entries\", [])\n",
        "\n",
        "                if not entries:\n",
        "                    print(f\"No workflows found in {repo_full}\")\n",
        "                    continue\n",
        "\n",
        "                save_folder = os.path.join(workflow_files, owner, repo_name)\n",
        "                os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "                for entry in entries:\n",
        "                    if entry[\"type\"] == \"blob\":\n",
        "                        filename = entry[\"name\"]\n",
        "                        content = entry[\"object\"][\"text\"]\n",
        "                        file_path = os.path.join(save_folder, filename)\n",
        "                        if content is not None:\n",
        "                            with open(file_path, \"w\") as f:\n",
        "                                f.write(content)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing chunk {start}-{end}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing chunk 0 to 50\n",
            "Processing chunk 50 to 100\n",
            "Processing chunk 100 to 150\n",
            "Processing chunk 150 to 200\n",
            "Processing chunk 200 to 250\n",
            "Processing chunk 250 to 300\n",
            "Processing chunk 300 to 350\n",
            "Processing chunk 350 to 400\n",
            "Processing chunk 400 to 450\n",
            "Processing chunk 450 to 500\n",
            "Processing chunk 500 to 550\n",
            "Processing chunk 550 to 600\n",
            "Processing chunk 600 to 650\n",
            "Processing chunk 650 to 700\n",
            "Processing chunk 700 to 750\n",
            "Processing chunk 750 to 800\n",
            "Processing chunk 800 to 850\n",
            "Processing chunk 850 to 900\n",
            "Processing chunk 900 to 950\n",
            "Processing chunk 950 to 1000\n",
            "Processing chunk 1000 to 1050\n",
            "Processing chunk 1050 to 1100\n",
            "Processing chunk 1100 to 1150\n",
            "Processing chunk 1150 to 1200\n",
            "Processing chunk 1200 to 1250\n",
            "Data missing monsternone/tmall-miao\n",
            "\n",
            "Processing chunk 1250 to 1300\n",
            "Processing chunk 1300 to 1350\n",
            "Processing chunk 1350 to 1400\n",
            "Processing chunk 1400 to 1450\n",
            "Processing chunk 1450 to 1500\n",
            "Processing chunk 1500 to 1550\n",
            "Processing chunk 1550 to 1600\n",
            "Processing chunk 1600 to 1650\n",
            "Processing chunk 1650 to 1700\n",
            "Processing chunk 1700 to 1750\n",
            "Processing chunk 1750 to 1800\n",
            "Processing chunk 1800 to 1850\n",
            "Processing chunk 1850 to 1900\n",
            "Processing chunk 1900 to 1950\n",
            "Processing chunk 1950 to 2000\n",
            "Processing chunk 2000 to 2050\n",
            "Processing chunk 2050 to 2100\n",
            "Processing chunk 2100 to 2150\n",
            "Processing chunk 2150 to 2200\n",
            "Processing chunk 2200 to 2250\n",
            "Processing chunk 2250 to 2300\n",
            "Processing chunk 2300 to 2350\n",
            "Processing chunk 2350 to 2400\n",
            "Processing chunk 2400 to 2450\n",
            "Processing chunk 2450 to 2500\n",
            "Processing chunk 2500 to 2550\n",
            "Processing chunk 2550 to 2600\n",
            "Processing chunk 2600 to 2650\n",
            "Processing chunk 2650 to 2700\n",
            "Processing chunk 2700 to 2750\n",
            "Processing chunk 2750 to 2800\n",
            "Processing chunk 2800 to 2850\n",
            "Processing chunk 2850 to 2900\n",
            "Processing chunk 2900 to 2950\n",
            "Processing chunk 2950 to 3000\n",
            "Processing chunk 3000 to 3050\n",
            "Processing chunk 3050 to 3100\n",
            "Processing chunk 3100 to 3150\n",
            "Processing chunk 3150 to 3200\n",
            "Processing chunk 3200 to 3250\n",
            "Processing chunk 3250 to 3300\n",
            "Processing chunk 3300 to 3350\n",
            "Processing chunk 3350 to 3400\n",
            "Processing chunk 3400 to 3450\n",
            "Processing chunk 3450 to 3500\n",
            "Processing chunk 3500 to 3550\n",
            "Processing chunk 3550 to 3600\n",
            "Processing chunk 3600 to 3650\n",
            "Processing chunk 3650 to 3700\n",
            "Processing chunk 3700 to 3750\n",
            "Processing chunk 3750 to 3800\n",
            "Processing chunk 3800 to 3850\n",
            "Processing chunk 3850 to 3900\n",
            "Processing chunk 3900 to 3950\n",
            "Processing chunk 3950 to 4000\n",
            "Processing chunk 4000 to 4050\n",
            "Processing chunk 4050 to 4100\n",
            "Processing chunk 4100 to 4150\n",
            "Processing chunk 4150 to 4200\n",
            "Processing chunk 4200 to 4250\n",
            "Processing chunk 4250 to 4300\n",
            "Processing chunk 4300 to 4350\n",
            "Processing chunk 4350 to 4400\n",
            "Processing chunk 4400 to 4450\n",
            "Processing chunk 4450 to 4500\n",
            "Processing chunk 4500 to 4550\n",
            "Processing chunk 4550 to 4600\n",
            "Processing chunk 4600 to 4650\n",
            "Processing chunk 4650 to 4700\n",
            "Processing chunk 4700 to 4750\n",
            "Processing chunk 4750 to 4800\n",
            "Processing chunk 4800 to 4850\n",
            "Processing chunk 4850 to 4900\n",
            "Processing chunk 4900 to 4950\n",
            "Processing chunk 4950 to 5000\n",
            "Processing chunk 5000 to 5050\n",
            "Processing chunk 5050 to 5100\n",
            "Processing chunk 5100 to 5150\n",
            "Processing chunk 5150 to 5200\n",
            "Processing chunk 5200 to 5250\n",
            "Processing chunk 5250 to 5300\n",
            "Processing chunk 5300 to 5350\n",
            "Processing chunk 5350 to 5400\n",
            "Processing chunk 5400 to 5450\n",
            "Processing chunk 5450 to 5500\n",
            "Processing chunk 5500 to 5550\n",
            "Processing chunk 5550 to 5600\n",
            "Processing chunk 5600 to 5650\n",
            "Processing chunk 5650 to 5700\n",
            "Processing chunk 5700 to 5750\n",
            "Processing chunk 5750 to 5800\n",
            "Processing chunk 5800 to 5850\n",
            "Processing chunk 5850 to 5900\n",
            "Processing chunk 5900 to 5950\n",
            "Data missing hjyssg/shigureader\n",
            "\n",
            "Processing chunk 5950 to 6000\n",
            "Processing chunk 6000 to 6050\n",
            "Processing chunk 6050 to 6100\n",
            "Processing chunk 6100 to 6150\n",
            "Processing chunk 6150 to 6200\n",
            "Processing chunk 6200 to 6250\n",
            "Processing chunk 6250 to 6300\n",
            "Processing chunk 6300 to 6350\n",
            "Processing chunk 6350 to 6400\n",
            "Processing chunk 6400 to 6450\n",
            "Processing chunk 6450 to 6500\n",
            "Processing chunk 6500 to 6550\n",
            "Processing chunk 6550 to 6600\n",
            "Processing chunk 6600 to 6650\n",
            "Processing chunk 6650 to 6700\n",
            "Processing chunk 6700 to 6750\n",
            "Processing chunk 6750 to 6800\n",
            "Processing chunk 6800 to 6850\n",
            "Processing chunk 6850 to 6900\n",
            "Processing chunk 6900 to 6950\n",
            "Processing chunk 6950 to 7000\n",
            "Processing chunk 7000 to 7050\n",
            "Processing chunk 7050 to 7100\n",
            "Processing chunk 7100 to 7150\n",
            "Processing chunk 7150 to 7200\n",
            "Processing chunk 7200 to 7250\n",
            "Processing chunk 7250 to 7300\n",
            "Processing chunk 7300 to 7350\n",
            "Processing chunk 7350 to 7400\n",
            "Processing chunk 7400 to 7450\n",
            "Processing chunk 7450 to 7500\n",
            "Processing chunk 7500 to 7550\n",
            "Processing chunk 7550 to 7600\n",
            "Processing chunk 7600 to 7650\n",
            "Processing chunk 7650 to 7700\n",
            "Processing chunk 7700 to 7750\n",
            "Processing chunk 7750 to 7800\n",
            "Processing chunk 7800 to 7850\n",
            "Processing chunk 7850 to 7900\n",
            "Processing chunk 7900 to 7950\n",
            "Processing chunk 7950 to 8000\n",
            "Processing chunk 8000 to 8050\n",
            "Processing chunk 8050 to 8100\n",
            "Processing chunk 8100 to 8150\n",
            "Processing chunk 8150 to 8200\n",
            "Processing chunk 8200 to 8250\n",
            "Data missing jayofelony/pwnagotchi\n",
            "\n",
            "Processing chunk 8250 to 8300\n",
            "Processing chunk 8300 to 8350\n",
            "Processing chunk 8350 to 8400\n",
            "Processing chunk 8400 to 8450\n",
            "Processing chunk 8450 to 8500\n",
            "Processing chunk 8500 to 8550\n",
            "Processing chunk 8550 to 8600\n",
            "Processing chunk 8600 to 8650\n",
            "Processing chunk 8650 to 8700\n",
            "Processing chunk 8700 to 8750\n",
            "Processing chunk 8750 to 8800\n",
            "Processing chunk 8800 to 8850\n",
            "Processing chunk 8850 to 8900\n",
            "Processing chunk 8900 to 8950\n",
            "Processing chunk 8950 to 9000\n",
            "Processing chunk 9000 to 9050\n",
            "Processing chunk 9050 to 9100\n",
            "Processing chunk 9100 to 9150\n",
            "Processing chunk 9150 to 9200\n",
            "Processing chunk 9200 to 9250\n",
            "Processing chunk 9250 to 9300\n",
            "Processing chunk 9300 to 9350\n",
            "Processing chunk 9350 to 9400\n",
            "Processing chunk 9400 to 9450\n",
            "Processing chunk 9450 to 9500\n",
            "Processing chunk 9500 to 9550\n",
            "Processing chunk 9550 to 9600\n",
            "Processing chunk 9600 to 9650\n",
            "Processing chunk 9650 to 9700\n",
            "Processing chunk 9700 to 9750\n",
            "Processing chunk 9750 to 9800\n",
            "Processing chunk 9800 to 9850\n",
            "Processing chunk 9850 to 9900\n",
            "Processing chunk 9900 to 9950\n",
            "Processing chunk 9950 to 10000\n",
            "Processing chunk 10000 to 10050\n",
            "Processing chunk 10050 to 10100\n",
            "Processing chunk 10100 to 10150\n",
            "Processing chunk 10150 to 10200\n",
            "Processing chunk 10200 to 10250\n",
            "Processing chunk 10250 to 10300\n",
            "Processing chunk 10300 to 10350\n",
            "Processing chunk 10350 to 10400\n",
            "Processing chunk 10400 to 10450\n",
            "Processing chunk 10450 to 10500\n",
            "Processing chunk 10500 to 10550\n",
            "Processing chunk 10550 to 10600\n",
            "Processing chunk 10600 to 10650\n",
            "Processing chunk 10650 to 10700\n",
            "Processing chunk 10700 to 10750\n",
            "Processing chunk 10750 to 10800\n",
            "Processing chunk 10800 to 10850\n",
            "Processing chunk 10850 to 10900\n",
            "Processing chunk 10900 to 10950\n",
            "Processing chunk 10950 to 11000\n",
            "Processing chunk 11000 to 11050\n",
            "Processing chunk 11050 to 11100\n",
            "Processing chunk 11100 to 11150\n",
            "Processing chunk 11150 to 11200\n",
            "Processing chunk 11200 to 11250\n",
            "Processing chunk 11250 to 11300\n",
            "Processing chunk 11300 to 11350\n",
            "Processing chunk 11350 to 11400\n",
            "Processing chunk 11400 to 11450\n",
            "Processing chunk 11450 to 11500\n",
            "Processing chunk 11500 to 11550\n",
            "Processing chunk 11550 to 11600\n",
            "Processing chunk 11600 to 11650\n",
            "Data missing nulldev/spendenr-ai-d\n",
            "\n",
            "Processing chunk 11650 to 11700\n",
            "Processing chunk 11700 to 11750\n",
            "Processing chunk 11750 to 11800\n",
            "Processing chunk 11800 to 11850\n",
            "Processing chunk 11850 to 11900\n",
            "Data missing cpinitiative/ide\n",
            "\n",
            "Processing chunk 11900 to 11950\n",
            "Processing chunk 11950 to 12000\n",
            "Processing chunk 12000 to 12050\n",
            "Processing chunk 12050 to 12100\n",
            "Processing chunk 12100 to 12150\n",
            "Processing chunk 12150 to 12200\n",
            "Processing chunk 12200 to 12215\n"
          ]
        }
      ],
      "source": [
        "download_workflows(repos_list_with_CI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total: 12210\n"
          ]
        }
      ],
      "source": [
        "def total_downloaded_workflows(root_folder):\n",
        "    result = []\n",
        "    for parent in os.listdir(root_folder):\n",
        "        parent_path = os.path.join(root_folder, parent)\n",
        "        if os.path.isdir(parent_path):\n",
        "            for child in os.listdir(parent_path):\n",
        "                child_path = os.path.join(parent_path, child)\n",
        "                if os.path.isdir(child_path):\n",
        "                    result.append(f\"{parent}/{child}\".lower())\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "root = \"workflow_files\"\n",
        "total_downloaded_workflow_list = total_downloaded_workflows(root)\n",
        "\n",
        "print(\"\\nTotal:\", len(total_downloaded_workflow_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_unretrieved_repos():\n",
        "    unretrieved_repos_list = []\n",
        "    for r in repos_list_with_CI:\n",
        "        if r not in total_downloaded_workflow_list:\n",
        "            unretrieved_repos_list.append(r)\n",
        "\n",
        "    print(\"Unretrieved:\", len(unretrieved_repos_list), unretrieved_repos_list)\n",
        "\n",
        "# reason is no .github/workflows folder or no workflows in the folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unretrieved: 5 ['monsternone/tmall-miao\\n', 'hjyssg/shigureader\\n', 'jayofelony/pwnagotchi\\n', 'nulldev/spendenr-ai-d\\n', 'cpinitiative/ide\\n']\n"
          ]
        }
      ],
      "source": [
        "get_unretrieved_repos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing chunk 0 to 5\n",
            "Data missing monsternone/tmall-miao\n",
            "\n",
            "Data missing hjyssg/shigureader\n",
            "\n",
            "Data missing jayofelony/pwnagotchi\n",
            "\n",
            "Data missing nulldev/spendenr-ai-d\n",
            "\n",
            "Data missing cpinitiative/ide\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download unretrieved repos: for network issues or other issues\n",
        "download_workflows(list(unretrieved_repos_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unretrieved: 5 ['monsternone/tmall-miao\\n', 'hjyssg/shigureader\\n', 'jayofelony/pwnagotchi\\n', 'nulldev/spendenr-ai-d\\n', 'cpinitiative/ide\\n']\n"
          ]
        }
      ],
      "source": [
        "get_unretrieved_repos()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
